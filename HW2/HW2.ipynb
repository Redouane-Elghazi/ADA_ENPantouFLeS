{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TopUniversities.com\n",
    "r = requests.get(\"https://www.topuniversities.com/sites/default/files/qs-rankings-data/357051.txt?_=1508602165358\")\n",
    "dic = r.json()['data']\n",
    "dic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for univ in dic[:200]:\n",
    "    #Get information from second page\n",
    "    r2 = requests.get(\"https://www.topuniversities.com\" + univ['url'])\n",
    "    univ['soup'] = BeautifulSoup(r2.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for univ in dic[:200]:\n",
    "    #First page information\n",
    "    row = {'Name':univ['title'],'Rank':univ['rank_display'],'Country':univ['country'],'Region':univ['region']}\n",
    "    \n",
    "    #Second page information\n",
    "    try:\n",
    "        row['Number of students'] = univ['soup'].find('div',class_ = \"total student\").find('div',class_=\"number\").string[1:-1]\n",
    "        row['Number of international students'] = univ['soup'].find('div',class_ = \"total inter\").find('div',class_=\"number\").string[1:-1]\n",
    "    \n",
    "        row['Number of faculty members'] = univ['soup'].find('div',class_ = \"total faculty\").find('div',class_=\"number\").string[1:-1]\n",
    "        row['Number of international members'] = univ['soup'].find('div',class_ = \"inter faculty\").find('div',class_=\"number\").string[1:-1]\n",
    "    except:\n",
    "        print(univ['title'], univ['rank_display'])\n",
    "        \n",
    "    data_list.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data_list)\n",
    "data = data[['Name','Rank','Country','Region','Number of faculty members','Number of international members','Number of students', 'Number of international students']]#'Number of faculty members','Number of international members']]\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "data\n",
    "\n",
    "#199-201 wrong -> should be 198-200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TimesHigherEducation\n",
    "\n",
    "r3 = requests.get(\"https://www.timeshighereducation.com/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json\")\n",
    "list_univ = r3.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_2 = pd.DataFrame(list_univ[:200])\n",
    "data_2 = data_2[['name','location','rank','stats_number_students','stats_pc_intl_students','stats_student_staff_ratio']]\n",
    "data_2.columns = ['Name','Country','Rank','Number of students','Percentage of international students','Students-Staff ratio']\n",
    "\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikibooks\n",
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]/max(len(s1),len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dummy'] = 1\n",
    "data_2['dummy'] = 1\n",
    "#Compressing 'University' and 'Institute'\n",
    "data['Name'] = data['Name'].apply(lambda x: x.replace('University','%').replace('Institute','#'))\n",
    "data_2['Name'] = data_2['Name'].apply(lambda x: x.replace('University','%').replace('Institute','#'))\n",
    "\n",
    "merge_data = pd.merge(data,data_2,on=['dummy'],suffixes=['_1','_2'])\n",
    "merge_data['dist'] = merge_data.apply(lambda x: levenshtein(x['Name_1'],x['Name_2']),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tronc = merge_data[merge_data['dist'] < 0.4][['Name_1','Name_2','dist']]\n",
    "data_tronc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from munkres import Munkres\n",
    "m = Munkres()\n",
    "names_1 = list(set(data_tronc['Name_1']))\n",
    "names_2 = list(set(data_tronc['Name_2']))\n",
    "index_1 = {val:i for i,val in enumerate(names_1)}\n",
    "index_2 = {val:i for i,val in enumerate(names_2)}\n",
    "matrix = [[1]*(len(names_1) + len(names_2)) for x in [0]*(len(names_1) + len(names_2))]\n",
    "\n",
    "for ind,x in data_tronc.iterrows():\n",
    "    matrix[index_1[x['Name_1']]][index_2[x['Name_2']]] = x['dist']\n",
    "indexes = m.compute(matrix)\n",
    "    \n",
    "pair = [[names_1[i],names_2[j]] for i,j in indexes if i < len(names_1) and j < len(names_2) and matrix[i][j] < 0.4]\n",
    "\n",
    "match_pair = pd.DataFrame(pair)\n",
    "match_pair.columns = ['Name_1','Name_2']\n",
    "match_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.columns = ['Name_1'] + list(data.columns)[1:]\n",
    "data_2.columns = ['Name_2'] + list(data_2.columns)[1:]\n",
    "\n",
    "data_left = pd.merge(data,match_pair,how='outer')\n",
    "data_left\n",
    "\n",
    "data_right = pd.merge(data_2,match_pair,how='outer')\n",
    "\n",
    "data_combined = pd.merge(data_left,data_right,how='outer',on=['Name_1','Name_2'],suffixes=['_1','_2'])\n",
    "data_combined = data_combined[['Name_1','Rank_1','Rank_2','Country_1','Region','Number of students_1','Number of students_2','Number of faculty members','Students-Staff ratio','Number of international members','Percentage of international students']]\n",
    "data_combined"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
